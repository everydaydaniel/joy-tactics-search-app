{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab All Patreon Post URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_episodes.csv created successfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.patreon.com/joytactics/posts'\n",
    "api_url = 'https://www.patreon.com/api/posts'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Referer': url\n",
    "}\n",
    "\n",
    "def fetch_campaign_id(session, url):\n",
    "    response = session.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    campaign_id_match = re.search(r'https://www\\.patreon\\.com/api/campaigns/(\\d+)', str(soup))\n",
    "    if campaign_id_match:\n",
    "        return campaign_id_match.group(1)\n",
    "    return None\n",
    "\n",
    "def fetch_posts(session, campaign_id, cursor=None):\n",
    "    params = {\n",
    "        'filter[campaign_id]': campaign_id,\n",
    "        'filter[contains_exclusive_posts]': 'true',\n",
    "        'sort': '-published_at'\n",
    "    }\n",
    "    if cursor:\n",
    "        params['page[cursor]'] = cursor\n",
    "    response = session.get(api_url, headers=headers, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def clean_title(title):\n",
    "    # Remove brackets and anything inside them\n",
    "    title = re.sub(r'\\[.*?\\]', '', title)\n",
    "    # Remove anything after and including the pipe symbol\n",
    "    title = re.split(r'\\|', title)[0]\n",
    "    # Replace spaces and hyphens with underscores\n",
    "    title = title.replace(' ', '_').replace('-', '_')\n",
    "    # Remove any non-alphanumeric characters except underscores\n",
    "    title = re.sub(r'[^a-zA-Z0-9_]', '', title)\n",
    "    # Remove trailing underscores\n",
    "    title = title.rstrip('_')\n",
    "    return title.lower()\n",
    "\n",
    "def parse_and_save_posts(data, rows):\n",
    "    posts = data.get('data', [])\n",
    "    for post in posts:\n",
    "        try:\n",
    "            title = post['attributes']['title']\n",
    "            published_at = post['attributes']['published_at']\n",
    "            patreon_url = post['attributes']['url']\n",
    "\n",
    "            # Clean title for raw_title\n",
    "            raw_title = re.sub(r'[^A-Za-z0-9 ]+', '', title).strip()\n",
    "\n",
    "            # Format title for formatted_title\n",
    "            formatted_title = clean_title(title)\n",
    "            \n",
    "            # Generate a random episode ID\n",
    "            episode_id = random.randint(1000, 9999)\n",
    "\n",
    "            # Convert the published_at to the desired format\n",
    "            date_posted = datetime.strptime(published_at, '%Y-%m-%dT%H:%M:%S.%f%z').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            rows.append([episode_id, date_posted, raw_title, formatted_title, patreon_url])\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError: {e} in post: {post}\")\n",
    "\n",
    "def save_to_csv(rows):\n",
    "    # Save to CSV\n",
    "    csv_columns = ['episode_id', 'date_posted', 'raw_title', 'formatted_title', 'patreon_url']\n",
    "    csv_file = \"data/raw_episodes.csv\"\n",
    "\n",
    "    try:\n",
    "        with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(csv_columns)\n",
    "            writer.writerows(rows)\n",
    "        print(\"raw_episodes.csv created successfully.\")\n",
    "    except IOError as e:\n",
    "        print(f\"I/O error: {e}\")\n",
    "\n",
    "with requests.Session() as s:\n",
    "    campaign_id = fetch_campaign_id(s, url)\n",
    "    if campaign_id:\n",
    "        rows = []\n",
    "        cursor = None\n",
    "        while True:\n",
    "            data = fetch_posts(s, campaign_id, cursor)\n",
    "            parse_and_save_posts(data, rows)\n",
    "            # Check for pagination cursor\n",
    "            cursor = data['meta']['pagination']['cursors'].get('next')\n",
    "            if not cursor:\n",
    "                break\n",
    "        save_to_csv(rows)\n",
    "    else:\n",
    "        print(\"Campaign ID not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Patreon Episodes and Video Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated episodes.csv successfully.\n",
      "Added transcript_title column and saved to episodes.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "input_file = 'data/raw_episodes.csv'\n",
    "output_file = 'data/episodes.csv'\n",
    "\n",
    "# Function to check if the raw title contains 'video' and does not contain 'audio'\n",
    "def check_video(title):\n",
    "    title_lower = title.lower()\n",
    "    return 'video' in title_lower and 'audio' not in title_lower\n",
    "\n",
    "# Function to check if the post was made on a Monday\n",
    "def check_bonus(date_str):\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    return date_obj.weekday() != 0\n",
    "\n",
    "# Function to generate transcript_title\n",
    "def generate_transcript_title(row):\n",
    "    date = pd.to_datetime(row['date_posted']).strftime('%Y%m%d')\n",
    "    return f\"{date}_{row['formatted_title']}\"\n",
    "\n",
    "# Read the existing episodes.csv to get current rows\n",
    "existing_rows = []\n",
    "try:\n",
    "    with open(output_file, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        existing_rows = list(reader)\n",
    "        existing_fieldnames = reader.fieldnames\n",
    "except FileNotFoundError:\n",
    "    print(f\"{output_file} not found. A new file will be created.\")\n",
    "    existing_fieldnames = None\n",
    "\n",
    "# Read the new rows from raw_episodes.csv\n",
    "with open(input_file, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    new_rows = list(reader)\n",
    "    raw_fieldnames = reader.fieldnames\n",
    "\n",
    "# Initialize existing_fieldnames if it was not found\n",
    "if existing_fieldnames is None:\n",
    "    existing_fieldnames = raw_fieldnames + ['video', 'bonus']\n",
    "\n",
    "# Add the 'video' and 'bonus' columns and filter out rows with existing dates\n",
    "for row in new_rows:\n",
    "    # Check if the row is already present and if 'video' and 'bonus' fields are filled out\n",
    "    existing_row = next((r for r in existing_rows if r['date_posted'] == row['date_posted']), None)\n",
    "    if existing_row and 'video' in existing_row and 'bonus' in existing_row:\n",
    "        continue\n",
    "    \n",
    "    row['video'] = check_video(row['raw_title'])\n",
    "    row['bonus'] = check_bonus(row['date_posted'])\n",
    "    existing_rows.append(row)\n",
    "\n",
    "# Write the combined data to episodes.csv\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=existing_fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(existing_rows)\n",
    "\n",
    "print(\"Updated episodes.csv successfully.\")\n",
    "\n",
    "# Now, load the episodes.csv with pandas to add the transcript_title column\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Add new column\n",
    "df['transcript_title'] = df.apply(generate_transcript_title, axis=1)\n",
    "\n",
    "# Ensure the original order of the columns is maintained\n",
    "df = df[existing_fieldnames + ['transcript_title']]\n",
    "\n",
    "# Save the modified DataFrame back to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Added transcript_title column and saved to episodes.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich w/ YouTube URL Using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████| 315/315 [00:00<00:00, 552574.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_file = 'data/episodes.csv'\n",
    "chromedriver_path = '/Users/isaacstevens/Downloads/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "# Set up the web driver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--incognito\")  # Open in incognito mode\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to log into Patreon\n",
    "def login_to_patreon(driver):\n",
    "    driver.get(\"https://www.patreon.com/login\")\n",
    "\n",
    "    # Define your login credentials\n",
    "    patreon_email = \"<YOUR-EMAIL\"\n",
    "    patreon_password = \"<YOUR-PATREON_PASSWORD\"\n",
    "\n",
    "    # Wait for the email input field to be present\n",
    "    email_input = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"email\"))\n",
    "    )\n",
    "    email_input.send_keys(patreon_email)\n",
    "\n",
    "    # Find and click the continue button\n",
    "    continue_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'hAAykn') and contains(., 'Continue')]\"))\n",
    "    )\n",
    "    continue_button.click()\n",
    "\n",
    "    # Wait for the password input field to be present\n",
    "    password_input = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"current-password\"))\n",
    "    )\n",
    "    password_input.send_keys(patreon_password)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the login process to complete\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'sc')]\"))\n",
    "    )\n",
    "    \n",
    "    # Add a brief wait to ensure the page has fully loaded\n",
    "    time.sleep(5)\n",
    "\n",
    "# Function to extract YouTube URL\n",
    "def extract_youtube_url(driver, patreon_url, formatted_title):\n",
    "    driver.get(patreon_url)\n",
    "    try:\n",
    "        iframe = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"iframe\"))\n",
    "        )\n",
    "        driver.switch_to.frame(iframe)\n",
    "        youtube_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//a[@title='Watch on YouTube']\"))\n",
    "        )\n",
    "        youtube_url = youtube_button.get_attribute(\"href\")\n",
    "        print(f\"Extracted YouTube URL for {formatted_title}: {youtube_url}\")\n",
    "        return youtube_url\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting YouTube URL for {patreon_url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Read the CSV file and process the data\n",
    "with open(input_file, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    rows = list(reader)\n",
    "\n",
    "    # Add 'youtube_url' column if not present\n",
    "    if 'youtube_url' not in reader.fieldnames:\n",
    "        for row in rows:\n",
    "            row['youtube_url'] = ''\n",
    "        fieldnames = reader.fieldnames + ['youtube_url']\n",
    "    else:\n",
    "        fieldnames = reader.fieldnames\n",
    "\n",
    "# Log into Patreon\n",
    "login_to_patreon(driver)\n",
    "\n",
    "# Process the rows with video and no YouTube URL using tqdm progress bar\n",
    "for row in tqdm(rows, desc=\"Processing episodes\"):\n",
    "    if row['video'] == 'True' and not row['youtube_url']:\n",
    "        print(f\"Executing episode: {row['formatted_title']}\")\n",
    "        youtube_url = extract_youtube_url(driver, row['patreon_url'], row['formatted_title'])\n",
    "        if youtube_url:\n",
    "            row['youtube_url'] = youtube_url\n",
    "\n",
    "            # Save the updated data back to the same CSV file immediately\n",
    "            with open(input_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(rows)\n",
    "            \n",
    "            print(f\"Updated CSV with YouTube URL for {row['formatted_title']}\")\n",
    "\n",
    "# Close the web driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
